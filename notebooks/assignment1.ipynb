{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> Batch : MSc 2020   Index no : 209334C   Name : B.K.S. Ishanka </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "def readFileWithSentenceTokenizer(filename):\n",
    "    with open(filename,'r', encoding=\"utf8\") as f:\n",
    "        content = f.read()\n",
    "    return sent_tokenize(content)\n",
    "\n",
    "def readFileLineByLine(filename):\n",
    "    with open(filename,'r', encoding=\"utf8\") as f:\n",
    "        content = f.read().splitlines()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reminds me of Liberal Immigration Fraudster Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#immigration #integration #canada https://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We want controlled immigration that contribute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the new Manitoba immigration fee a head tax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada immigration profit influence modernisti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0  Reminds me of Liberal Immigration Fraudster Mo...\n",
       "1  #immigration #integration #canada https://t.co...\n",
       "2  We want controlled immigration that contribute...\n",
       "3  Is the new Manitoba immigration fee a head tax...\n",
       "4  Canada immigration profit influence modernisti..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.DataFrame(readFileLineByLine('dataset/twitter_data.txt'), columns =['tweets']) \n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_course_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honestly last seven lectures are good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lectures are understandable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lecture slides are very useful to self-study a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good :) \\n&lt;br /&gt;please do recap at class star...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             student_course_feedback\n",
       "0             Honestly last seven lectures are good.\n",
       "1                       Lectures are understandable.\n",
       "2  Lecture slides are very useful to self-study a...\n",
       "3  The given opportunity to ask questions from th...\n",
       "4  \"Good :) \\n<br />please do recap at class star..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_course_feedback_df = pd.DataFrame(readFileWithSentenceTokenizer('dataset/student_course_feedback.txt'), columns =['student_course_feedback']) \n",
    "student_course_feedback_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural network models have shown their promisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, in most existing approaches, the extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this paper, we propose an adversarial multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We conduct extensive experiments on 16 differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Besides, we show that the\\nshared knowledge le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      research_paper\n",
       "0  Neural network models have shown their promisi...\n",
       "1  However, in most existing approaches, the extr...\n",
       "2  In this paper, we propose an adversarial multi...\n",
       "3  We conduct extensive experiments on 16 differe...\n",
       "4  Besides, we show that the\\nshared knowledge le..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_paper_df = pd.DataFrame(readFileWithSentenceTokenizer('dataset/research_paper.txt'), columns =['research_paper']) \n",
    "research_paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reminds me of Liberal Immigration Fraudster Mo...</td>\n",
       "      <td>[Reminds, me, of, Liberal, Immigration, Frauds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#immigration #integration #canada https://t.co...</td>\n",
       "      <td>[#immigration, #integration, #canada, https://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We want controlled immigration that contribute...</td>\n",
       "      <td>[We, want, controlled, immigration, that, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the new Manitoba immigration fee a head tax...</td>\n",
       "      <td>[Is, the, new, Manitoba, immigration, fee, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada immigration profit influence modernisti...</td>\n",
       "      <td>[Canada, immigration, profit, influence, moder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0  Reminds me of Liberal Immigration Fraudster Mo...   \n",
       "1  #immigration #integration #canada https://t.co...   \n",
       "2  We want controlled immigration that contribute...   \n",
       "3  Is the new Manitoba immigration fee a head tax...   \n",
       "4  Canada immigration profit influence modernisti...   \n",
       "\n",
       "                                    tokenized_tweets  \n",
       "0  [Reminds, me, of, Liberal, Immigration, Frauds...  \n",
       "1  [#immigration, #integration, #canada, https://...  \n",
       "2  [We, want, controlled, immigration, that, cont...  \n",
       "3  [Is, the, new, Manitoba, immigration, fee, a, ...  \n",
       "4  [Canada, immigration, profit, influence, moder...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[\"tokenized_tweets\"] = twitter_df.apply(lambda x: TweetTokenizer().tokenize(x.tweets),axis=1)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_course_feedback</th>\n",
       "      <th>tokenized_student_course_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honestly last seven lectures are good.</td>\n",
       "      <td>[Honestly, last, seven, lectures, are, good, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lectures are understandable.</td>\n",
       "      <td>[Lectures, are, understandable, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lecture slides are very useful to self-study a...</td>\n",
       "      <td>[Lecture, slides, are, very, useful, to, self-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "      <td>[The, given, opportunity, to, ask, questions, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good :) \\n&lt;br /&gt;please do recap at class star...</td>\n",
       "      <td>[``, Good, :, ), &lt;, br, /, &gt;, please, do, reca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             student_course_feedback  \\\n",
       "0             Honestly last seven lectures are good.   \n",
       "1                       Lectures are understandable.   \n",
       "2  Lecture slides are very useful to self-study a...   \n",
       "3  The given opportunity to ask questions from th...   \n",
       "4  \"Good :) \\n<br />please do recap at class star...   \n",
       "\n",
       "                   tokenized_student_course_feedback  \n",
       "0    [Honestly, last, seven, lectures, are, good, .]  \n",
       "1                 [Lectures, are, understandable, .]  \n",
       "2  [Lecture, slides, are, very, useful, to, self-...  \n",
       "3  [The, given, opportunity, to, ask, questions, ...  \n",
       "4  [``, Good, :, ), <, br, /, >, please, do, reca...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_course_feedback_df[\"tokenized_student_course_feedback\"] = student_course_feedback_df.apply(lambda x: word_tokenize(x.student_course_feedback),axis=1)\n",
    "student_course_feedback_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_paper</th>\n",
       "      <th>tokenized_research_paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural network models have shown their promisi...</td>\n",
       "      <td>[Neural, network, models, have, shown, their, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, in most existing approaches, the extr...</td>\n",
       "      <td>[However, ,, in, most, existing, approaches, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this paper, we propose an adversarial multi...</td>\n",
       "      <td>[In, this, paper, ,, we, propose, an, adversar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We conduct extensive experiments on 16 differe...</td>\n",
       "      <td>[We, conduct, extensive, experiments, on, 16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Besides, we show that the\\nshared knowledge le...</td>\n",
       "      <td>[Besides, ,, we, show, that, the, shared, know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      research_paper  \\\n",
       "0  Neural network models have shown their promisi...   \n",
       "1  However, in most existing approaches, the extr...   \n",
       "2  In this paper, we propose an adversarial multi...   \n",
       "3  We conduct extensive experiments on 16 differe...   \n",
       "4  Besides, we show that the\\nshared knowledge le...   \n",
       "\n",
       "                            tokenized_research_paper  \n",
       "0  [Neural, network, models, have, shown, their, ...  \n",
       "1  [However, ,, in, most, existing, approaches, ,...  \n",
       "2  [In, this, paper, ,, we, propose, an, adversar...  \n",
       "3  [We, conduct, extensive, experiments, on, 16, ...  \n",
       "4  [Besides, ,, we, show, that, the, shared, know...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_paper_df[\"tokenized_research_paper\"] = research_paper_df.apply(lambda x: word_tokenize(x.research_paper),axis=1)\n",
    "research_paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#https://spacy.io/universe/project/contextualSpellCheck\n",
    "import contextualSpellCheck\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "contextualSpellCheck.add_to_pipe(nlp)\n",
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>iolated_word_correction</th>\n",
       "      <th>contextual_word_correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reminds me of Liberal Immigration Fraudster Mo...</td>\n",
       "      <td>[Reminds, me, of, Liberal, Immigration, Frauds...</td>\n",
       "      <td>Reminds me of Liberal Immigration Fraudster Mo...</td>\n",
       "      <td>Reminds me of Liberal Immigration Minister for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#immigration #integration #canada https://t.co...</td>\n",
       "      <td>[#immigration, #integration, #canada, https://...</td>\n",
       "      <td>#immigration #integration #canada http://t.co/...</td>\n",
       "      <td>#immigration #integration #visa https://t.co/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We want controlled immigration that contribute...</td>\n",
       "      <td>[We, want, controlled, immigration, that, cont...</td>\n",
       "      <td>We want controlled immigration that contribute...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the new Manitoba immigration fee a head tax...</td>\n",
       "      <td>[Is, the, new, Manitoba, immigration, fee, a, ...</td>\n",
       "      <td>Is the new Manitoba immigration fee a head tax...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada immigration profit influence modernisti...</td>\n",
       "      <td>[Canada, immigration, profit, influence, moder...</td>\n",
       "      <td>Canada immigration profit influence modernisti...</td>\n",
       "      <td>Canada immigration profit influence for ideas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0  Reminds me of Liberal Immigration Fraudster Mo...   \n",
       "1  #immigration #integration #canada https://t.co...   \n",
       "2  We want controlled immigration that contribute...   \n",
       "3  Is the new Manitoba immigration fee a head tax...   \n",
       "4  Canada immigration profit influence modernisti...   \n",
       "\n",
       "                                    tokenized_tweets  \\\n",
       "0  [Reminds, me, of, Liberal, Immigration, Frauds...   \n",
       "1  [#immigration, #integration, #canada, https://...   \n",
       "2  [We, want, controlled, immigration, that, cont...   \n",
       "3  [Is, the, new, Manitoba, immigration, fee, a, ...   \n",
       "4  [Canada, immigration, profit, influence, moder...   \n",
       "\n",
       "                             iolated_word_correction  \\\n",
       "0  Reminds me of Liberal Immigration Fraudster Mo...   \n",
       "1  #immigration #integration #canada http://t.co/...   \n",
       "2  We want controlled immigration that contribute...   \n",
       "3  Is the new Manitoba immigration fee a head tax...   \n",
       "4  Canada immigration profit influence modernisti...   \n",
       "\n",
       "                          contextual_word_correction  \n",
       "0  Reminds me of Liberal Immigration Minister for...  \n",
       "1  #immigration #integration #visa https://t.co/M...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4  Canada immigration profit influence for ideas ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[\"iolated_word_correction\"] = twitter_df.apply(lambda x: ' '.join([ spell(tokens) for tokens in x.tokenized_tweets]),axis=1)\n",
    "twitter_df[\"contextual_word_correction\"] = twitter_df.apply(lambda x: nlp(x.tweets)._.outcome_spellCheck,axis=1)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_course_feedback</th>\n",
       "      <th>tokenized_student_course_feedback</th>\n",
       "      <th>iolated_word_correction</th>\n",
       "      <th>contextual_word_correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honestly last seven lectures are good.</td>\n",
       "      <td>[Honestly, last, seven, lectures, are, good, .]</td>\n",
       "      <td>Honestly last seven lectures are good .</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lectures are understandable.</td>\n",
       "      <td>[Lectures, are, understandable, .]</td>\n",
       "      <td>Lectures are understandable .</td>\n",
       "      <td>Lectures are available.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lecture slides are very useful to self-study a...</td>\n",
       "      <td>[Lecture, slides, are, very, useful, to, self-...</td>\n",
       "      <td>Lecture slides are very useful to self-study a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "      <td>[The, given, opportunity, to, ask, questions, ...</td>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good :) \\n&lt;br /&gt;please do recap at class star...</td>\n",
       "      <td>[``, Good, :, ), &lt;, br, /, &gt;, please, do, reca...</td>\n",
       "      <td>`` Good : ) &lt; br / &gt; please do recap at class ...</td>\n",
       "      <td>\"Good :) \\n&lt;br Please do that at class startin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             student_course_feedback  \\\n",
       "0             Honestly last seven lectures are good.   \n",
       "1                       Lectures are understandable.   \n",
       "2  Lecture slides are very useful to self-study a...   \n",
       "3  The given opportunity to ask questions from th...   \n",
       "4  \"Good :) \\n<br />please do recap at class star...   \n",
       "\n",
       "                   tokenized_student_course_feedback  \\\n",
       "0    [Honestly, last, seven, lectures, are, good, .]   \n",
       "1                 [Lectures, are, understandable, .]   \n",
       "2  [Lecture, slides, are, very, useful, to, self-...   \n",
       "3  [The, given, opportunity, to, ask, questions, ...   \n",
       "4  [``, Good, :, ), <, br, /, >, please, do, reca...   \n",
       "\n",
       "                             iolated_word_correction  \\\n",
       "0            Honestly last seven lectures are good .   \n",
       "1                      Lectures are understandable .   \n",
       "2  Lecture slides are very useful to self-study a...   \n",
       "3  The given opportunity to ask questions from th...   \n",
       "4  `` Good : ) < br / > please do recap at class ...   \n",
       "\n",
       "                          contextual_word_correction  \n",
       "0                                                     \n",
       "1                            Lectures are available.  \n",
       "2                                                     \n",
       "3  The given opportunity to ask questions from th...  \n",
       "4  \"Good :) \\n<br Please do that at class startin...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_course_feedback_df[\"iolated_word_correction\"] = student_course_feedback_df.apply(lambda x: ' '.join([ spell(tokens) for tokens in x.tokenized_student_course_feedback]),axis=1)\n",
    "student_course_feedback_df[\"contextual_word_correction\"] = student_course_feedback_df.apply(lambda x: nlp(x.student_course_feedback)._.outcome_spellCheck,axis=1)\n",
    "student_course_feedback_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_paper</th>\n",
       "      <th>tokenized_research_paper</th>\n",
       "      <th>iolated_word_correction</th>\n",
       "      <th>contextual_word_correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural network models have shown their promisi...</td>\n",
       "      <td>[Neural, network, models, have, shown, their, ...</td>\n",
       "      <td>Neural network models have shown their promisi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, in most existing approaches, the extr...</td>\n",
       "      <td>[However, ,, in, most, existing, approaches, ,...</td>\n",
       "      <td>However , in most existing approaches , the ex...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this paper, we propose an adversarial multi...</td>\n",
       "      <td>[In, this, paper, ,, we, propose, an, adversar...</td>\n",
       "      <td>In this paper , we propose an adversarial mult...</td>\n",
       "      <td>In this paper, we propose an alternative multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We conduct extensive experiments on 16 differe...</td>\n",
       "      <td>[We, conduct, extensive, experiments, on, 16, ...</td>\n",
       "      <td>We conduct extensive experiments on 16 differe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Besides, we show that the\\nshared knowledge le...</td>\n",
       "      <td>[Besides, ,, we, show, that, the, shared, know...</td>\n",
       "      <td>Besides , we show that the shared knowledge le...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      research_paper  \\\n",
       "0  Neural network models have shown their promisi...   \n",
       "1  However, in most existing approaches, the extr...   \n",
       "2  In this paper, we propose an adversarial multi...   \n",
       "3  We conduct extensive experiments on 16 differe...   \n",
       "4  Besides, we show that the\\nshared knowledge le...   \n",
       "\n",
       "                            tokenized_research_paper  \\\n",
       "0  [Neural, network, models, have, shown, their, ...   \n",
       "1  [However, ,, in, most, existing, approaches, ,...   \n",
       "2  [In, this, paper, ,, we, propose, an, adversar...   \n",
       "3  [We, conduct, extensive, experiments, on, 16, ...   \n",
       "4  [Besides, ,, we, show, that, the, shared, know...   \n",
       "\n",
       "                             iolated_word_correction  \\\n",
       "0  Neural network models have shown their promisi...   \n",
       "1  However , in most existing approaches , the ex...   \n",
       "2  In this paper , we propose an adversarial mult...   \n",
       "3  We conduct extensive experiments on 16 differe...   \n",
       "4  Besides , we show that the shared knowledge le...   \n",
       "\n",
       "                          contextual_word_correction  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  In this paper, we propose an alternative multi...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_paper_df[\"iolated_word_correction\"] = research_paper_df.apply(lambda x: ' '.join([ spell(tokens) for tokens in x.tokenized_research_paper]),axis=1)\n",
    "research_paper_df[\"contextual_word_correction\"] = research_paper_df.apply(lambda x: nlp(x.research_paper)._.outcome_spellCheck,axis=1)\n",
    "research_paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer() \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "le = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>iolated_word_correction</th>\n",
       "      <th>contextual_word_correction</th>\n",
       "      <th>stemmed_words</th>\n",
       "      <th>lemmatized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reminds me of Liberal Immigration Fraudster Mo...</td>\n",
       "      <td>[Reminds, me, of, Liberal, Immigration, Frauds...</td>\n",
       "      <td>Reminds me of Liberal Immigration Fraudster Mo...</td>\n",
       "      <td>Reminds me of Liberal Immigration Minister for...</td>\n",
       "      <td>remind me of liber immigr fraudster monsef avo...</td>\n",
       "      <td>Reminds me of Liberal Immigration Fraudster Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#immigration #integration #canada https://t.co...</td>\n",
       "      <td>[#immigration, #integration, #canada, https://...</td>\n",
       "      <td>#immigration #integration #canada http://t.co/...</td>\n",
       "      <td>#immigration #integration #visa https://t.co/M...</td>\n",
       "      <td>#immigr #integr #canada https://t.co/m5ckgyvv8f</td>\n",
       "      <td>#immigration #integration #canada https://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We want controlled immigration that contribute...</td>\n",
       "      <td>[We, want, controlled, immigration, that, cont...</td>\n",
       "      <td>We want controlled immigration that contribute...</td>\n",
       "      <td></td>\n",
       "      <td>We want control immigr that contribut posit to...</td>\n",
       "      <td>We want controlled immigration that contribute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the new Manitoba immigration fee a head tax...</td>\n",
       "      <td>[Is, the, new, Manitoba, immigration, fee, a, ...</td>\n",
       "      <td>Is the new Manitoba immigration fee a head tax...</td>\n",
       "      <td></td>\n",
       "      <td>Is the new manitoba immigr fee a head tax ? ht...</td>\n",
       "      <td>Is the new Manitoba immigration fee a head tax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada immigration profit influence modernisti...</td>\n",
       "      <td>[Canada, immigration, profit, influence, moder...</td>\n",
       "      <td>Canada immigration profit influence modernisti...</td>\n",
       "      <td>Canada immigration profit influence for ideas ...</td>\n",
       "      <td>canada immigr profit influenc modernist delhi ...</td>\n",
       "      <td>Canada immigration profit influence modernisti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  \\\n",
       "0  Reminds me of Liberal Immigration Fraudster Mo...   \n",
       "1  #immigration #integration #canada https://t.co...   \n",
       "2  We want controlled immigration that contribute...   \n",
       "3  Is the new Manitoba immigration fee a head tax...   \n",
       "4  Canada immigration profit influence modernisti...   \n",
       "\n",
       "                                    tokenized_tweets  \\\n",
       "0  [Reminds, me, of, Liberal, Immigration, Frauds...   \n",
       "1  [#immigration, #integration, #canada, https://...   \n",
       "2  [We, want, controlled, immigration, that, cont...   \n",
       "3  [Is, the, new, Manitoba, immigration, fee, a, ...   \n",
       "4  [Canada, immigration, profit, influence, moder...   \n",
       "\n",
       "                             iolated_word_correction  \\\n",
       "0  Reminds me of Liberal Immigration Fraudster Mo...   \n",
       "1  #immigration #integration #canada http://t.co/...   \n",
       "2  We want controlled immigration that contribute...   \n",
       "3  Is the new Manitoba immigration fee a head tax...   \n",
       "4  Canada immigration profit influence modernisti...   \n",
       "\n",
       "                          contextual_word_correction  \\\n",
       "0  Reminds me of Liberal Immigration Minister for...   \n",
       "1  #immigration #integration #visa https://t.co/M...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Canada immigration profit influence for ideas ...   \n",
       "\n",
       "                                       stemmed_words  \\\n",
       "0  remind me of liber immigr fraudster monsef avo...   \n",
       "1    #immigr #integr #canada https://t.co/m5ckgyvv8f   \n",
       "2  We want control immigr that contribut posit to...   \n",
       "3  Is the new manitoba immigr fee a head tax ? ht...   \n",
       "4  canada immigr profit influenc modernist delhi ...   \n",
       "\n",
       "                                    lemmatized_words  \n",
       "0  Reminds me of Liberal Immigration Fraudster Mo...  \n",
       "1  #immigration #integration #canada https://t.co...  \n",
       "2  We want controlled immigration that contribute...  \n",
       "3  Is the new Manitoba immigration fee a head tax...  \n",
       "4  Canada immigration profit influence modernisti...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[\"stemmed_words\"] = twitter_df.apply(lambda x: ' '.join([ ps.stem(tokens) for tokens in x.tokenized_tweets]),axis=1)\n",
    "twitter_df[\"lemmatized_words\"] = twitter_df.apply(lambda x: ' '.join([ le.lemmatize(tokens) for tokens in x.tokenized_tweets]),axis=1)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_course_feedback</th>\n",
       "      <th>tokenized_student_course_feedback</th>\n",
       "      <th>iolated_word_correction</th>\n",
       "      <th>contextual_word_correction</th>\n",
       "      <th>stemmed_words</th>\n",
       "      <th>lemmatized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honestly last seven lectures are good.</td>\n",
       "      <td>[Honestly, last, seven, lectures, are, good, .]</td>\n",
       "      <td>Honestly last seven lectures are good .</td>\n",
       "      <td></td>\n",
       "      <td>honestli last seven lectur are good .</td>\n",
       "      <td>Honestly last seven lecture are good .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lectures are understandable.</td>\n",
       "      <td>[Lectures, are, understandable, .]</td>\n",
       "      <td>Lectures are understandable .</td>\n",
       "      <td>Lectures are available.</td>\n",
       "      <td>lectur are understand .</td>\n",
       "      <td>Lectures are understandable .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lecture slides are very useful to self-study a...</td>\n",
       "      <td>[Lecture, slides, are, very, useful, to, self-...</td>\n",
       "      <td>Lecture slides are very useful to self-study a...</td>\n",
       "      <td></td>\n",
       "      <td>lectur slide are veri use to self-studi also .</td>\n",
       "      <td>Lecture slide are very useful to self-study al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "      <td>[The, given, opportunity, to, ask, questions, ...</td>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "      <td>The given opportunity to ask questions from th...</td>\n",
       "      <td>the given opportun to ask question from the le...</td>\n",
       "      <td>The given opportunity to ask question from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Good :) \\n&lt;br /&gt;please do recap at class star...</td>\n",
       "      <td>[``, Good, :, ), &lt;, br, /, &gt;, please, do, reca...</td>\n",
       "      <td>`` Good : ) &lt; br / &gt; please do recap at class ...</td>\n",
       "      <td>\"Good :) \\n&lt;br Please do that at class startin...</td>\n",
       "      <td>`` good : ) &lt; br / &gt; pleas do recap at class s...</td>\n",
       "      <td>`` Good : ) &lt; br / &gt; please do recap at class ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             student_course_feedback  \\\n",
       "0             Honestly last seven lectures are good.   \n",
       "1                       Lectures are understandable.   \n",
       "2  Lecture slides are very useful to self-study a...   \n",
       "3  The given opportunity to ask questions from th...   \n",
       "4  \"Good :) \\n<br />please do recap at class star...   \n",
       "\n",
       "                   tokenized_student_course_feedback  \\\n",
       "0    [Honestly, last, seven, lectures, are, good, .]   \n",
       "1                 [Lectures, are, understandable, .]   \n",
       "2  [Lecture, slides, are, very, useful, to, self-...   \n",
       "3  [The, given, opportunity, to, ask, questions, ...   \n",
       "4  [``, Good, :, ), <, br, /, >, please, do, reca...   \n",
       "\n",
       "                             iolated_word_correction  \\\n",
       "0            Honestly last seven lectures are good .   \n",
       "1                      Lectures are understandable .   \n",
       "2  Lecture slides are very useful to self-study a...   \n",
       "3  The given opportunity to ask questions from th...   \n",
       "4  `` Good : ) < br / > please do recap at class ...   \n",
       "\n",
       "                          contextual_word_correction  \\\n",
       "0                                                      \n",
       "1                            Lectures are available.   \n",
       "2                                                      \n",
       "3  The given opportunity to ask questions from th...   \n",
       "4  \"Good :) \\n<br Please do that at class startin...   \n",
       "\n",
       "                                       stemmed_words  \\\n",
       "0              honestli last seven lectur are good .   \n",
       "1                            lectur are understand .   \n",
       "2     lectur slide are veri use to self-studi also .   \n",
       "3  the given opportun to ask question from the le...   \n",
       "4  `` good : ) < br / > pleas do recap at class s...   \n",
       "\n",
       "                                    lemmatized_words  \n",
       "0             Honestly last seven lecture are good .  \n",
       "1                      Lectures are understandable .  \n",
       "2  Lecture slide are very useful to self-study al...  \n",
       "3  The given opportunity to ask question from the...  \n",
       "4  `` Good : ) < br / > please do recap at class ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_course_feedback_df[\"stemmed_words\"] = student_course_feedback_df.apply(lambda x: ' '.join([ ps.stem(tokens) for tokens in x.tokenized_student_course_feedback]),axis=1)\n",
    "student_course_feedback_df[\"lemmatized_words\"] = student_course_feedback_df.apply(lambda x: ' '.join([ le.lemmatize(tokens) for tokens in x.tokenized_student_course_feedback]),axis=1)\n",
    "student_course_feedback_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_paper</th>\n",
       "      <th>tokenized_research_paper</th>\n",
       "      <th>iolated_word_correction</th>\n",
       "      <th>contextual_word_correction</th>\n",
       "      <th>stemmed_words</th>\n",
       "      <th>lemmatized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural network models have shown their promisi...</td>\n",
       "      <td>[Neural, network, models, have, shown, their, ...</td>\n",
       "      <td>Neural network models have shown their promisi...</td>\n",
       "      <td></td>\n",
       "      <td>neural network model have shown their promis o...</td>\n",
       "      <td>Neural network model have shown their promisin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, in most existing approaches, the extr...</td>\n",
       "      <td>[However, ,, in, most, existing, approaches, ,...</td>\n",
       "      <td>However , in most existing approaches , the ex...</td>\n",
       "      <td></td>\n",
       "      <td>howev , in most exist approach , the extract s...</td>\n",
       "      <td>However , in most existing approach , the extr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this paper, we propose an adversarial multi...</td>\n",
       "      <td>[In, this, paper, ,, we, propose, an, adversar...</td>\n",
       "      <td>In this paper , we propose an adversarial mult...</td>\n",
       "      <td>In this paper, we propose an alternative multi...</td>\n",
       "      <td>In thi paper , we propos an adversari multi-ta...</td>\n",
       "      <td>In this paper , we propose an adversarial mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We conduct extensive experiments on 16 differe...</td>\n",
       "      <td>[We, conduct, extensive, experiments, on, 16, ...</td>\n",
       "      <td>We conduct extensive experiments on 16 differe...</td>\n",
       "      <td></td>\n",
       "      <td>We conduct extens experi on 16 differ text cla...</td>\n",
       "      <td>We conduct extensive experiment on 16 differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Besides, we show that the\\nshared knowledge le...</td>\n",
       "      <td>[Besides, ,, we, show, that, the, shared, know...</td>\n",
       "      <td>Besides , we show that the shared knowledge le...</td>\n",
       "      <td></td>\n",
       "      <td>besid , we show that the share knowledg learn ...</td>\n",
       "      <td>Besides , we show that the shared knowledge le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      research_paper  \\\n",
       "0  Neural network models have shown their promisi...   \n",
       "1  However, in most existing approaches, the extr...   \n",
       "2  In this paper, we propose an adversarial multi...   \n",
       "3  We conduct extensive experiments on 16 differe...   \n",
       "4  Besides, we show that the\\nshared knowledge le...   \n",
       "\n",
       "                            tokenized_research_paper  \\\n",
       "0  [Neural, network, models, have, shown, their, ...   \n",
       "1  [However, ,, in, most, existing, approaches, ,...   \n",
       "2  [In, this, paper, ,, we, propose, an, adversar...   \n",
       "3  [We, conduct, extensive, experiments, on, 16, ...   \n",
       "4  [Besides, ,, we, show, that, the, shared, know...   \n",
       "\n",
       "                             iolated_word_correction  \\\n",
       "0  Neural network models have shown their promisi...   \n",
       "1  However , in most existing approaches , the ex...   \n",
       "2  In this paper , we propose an adversarial mult...   \n",
       "3  We conduct extensive experiments on 16 differe...   \n",
       "4  Besides , we show that the shared knowledge le...   \n",
       "\n",
       "                          contextual_word_correction  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  In this paper, we propose an alternative multi...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                       stemmed_words  \\\n",
       "0  neural network model have shown their promis o...   \n",
       "1  howev , in most exist approach , the extract s...   \n",
       "2  In thi paper , we propos an adversari multi-ta...   \n",
       "3  We conduct extens experi on 16 differ text cla...   \n",
       "4  besid , we show that the share knowledg learn ...   \n",
       "\n",
       "                                    lemmatized_words  \n",
       "0  Neural network model have shown their promisin...  \n",
       "1  However , in most existing approach , the extr...  \n",
       "2  In this paper , we propose an adversarial mult...  \n",
       "3  We conduct extensive experiment on 16 differen...  \n",
       "4  Besides , we show that the shared knowledge le...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_paper_df[\"stemmed_words\"] = research_paper_df.apply(lambda x: ' '.join([ ps.stem(tokens) for tokens in x.tokenized_research_paper]),axis=1)\n",
    "research_paper_df[\"lemmatized_words\"] = research_paper_df.apply(lambda x: ' '.join([ le.lemmatize(tokens) for tokens in x.tokenized_research_paper]),axis=1)\n",
    "research_paper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.to_csv(\"dataset/twitter_processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_course_feedback_df.to_csv(\"dataset/student_course_feedback_processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper_df.to_csv(\"dataset/research_paper_processed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
